{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54a45bcc",
   "metadata": {},
   "source": [
    "# Classification. Part 2\n",
    "---\n",
    "Author: Anatoliy Durkin\n",
    "\n",
    "Updated: 17.03.2025\n",
    "\n",
    "---\n",
    "В данном ноутбуке будут рассмотрены несколько моделей классификации, новые функции для метрик и сами новые метрики, а также будет уделено внимание подбору гиперпараметров для моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd24dbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9233e9e3",
   "metadata": {},
   "source": [
    "В прошлом ноутбуке мы писали функцию, выводившую все необходимые нам метрики вместе. Мы импортировали несколько функций, но в этом ноутбуке используем только две: `confusion_matrix` выводит матрицу ошибок, а `classification_report` выдает остальные метрики, увидим уже на примере. Зачем нужен `fill_diagonal`, увидим в конце ноутбука."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df50372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(target, pred, fill=False):\n",
    "    print(classification_report(target, pred))\n",
    "    matrix = np.array(confusion_matrix(target, pred))\n",
    "    if fill:\n",
    "        np.fill_diagonal(matrix, 0)\n",
    "    sns.heatmap(matrix, annot=True, fmt='.0f')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Матрица ошибок')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266d0516",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "---\n",
    "\n",
    "Знаете ли вы метод \"съешь лягушку\"? Это о том, что нужно выполнить самую неприятную задачу сразу, не откладывая. Так что съедим лягушку и слегка окунёмся в NLP, или Natural language processing - обработка естественного языка.\n",
    "\n",
    "В этой сфере может быть множество задач классификации, например, отделение спама. Но мы рассмотрим задачу определения кликбейта среди новостных заголовков.\n",
    "\n",
    "> Кликбейт (англ. clickbait от click «щелчок» + bait «приманка») — уничижительный термин, описывающий веб-контент, целью которого является получение дохода от онлайн-рекламы, особенно в ущерб качеству или точности информации.\n",
    "\n",
    "А как модель используем наивный байессовский классиикатор.\n",
    "\n",
    "Итак, познакомимся с данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc1fa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = pd.read_csv('titles_data.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b260c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc20e1bc",
   "metadata": {},
   "source": [
    "Поделим выборку на обучающую и тестовую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042bebde",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(titles['titles'], titles['target'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52184036",
   "metadata": {},
   "source": [
    "Конечно, модели не могут просто так работать с обычным текстом. Необходимы какие-то преобразования. Все модели спокойно работают с числами, значит нужно превратить текст в числа. И тут есть два важных процесса: токенизация и векторизация.\n",
    "\n",
    "> Токенизация — процесс разбиения текстового документа на отдельные слова, которые называются токенами.\n",
    "\n",
    "> Векторизация – это термин, обозначающий классический подход к преобразованию входных данных из их исходного формата (например, текста) в векторы действительных чисел, которые понятны моделям машинного обучения.\n",
    "\n",
    "---\n",
    "Как мы применим это к нашим данным?\n",
    "\n",
    "Например, для определения кликбейта можно посчитать, как часто слова встречаются в заголовках. Скорее всего определенные слова могут сигнализировать нам о кликбейте.\n",
    "\n",
    "В этом нам может помочь `CountVectorizer`, который считает, сколько раз каждое слово встречается в определенной строке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ce00bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729c85b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = ['мама мыла раму',\n",
    "      'мама чинила раму',\n",
    "      'мама мыла, мама чинила']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f749cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "txt = vectorizer.fit_transform(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b199904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# результат\n",
    "txt.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2beb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# словарь\n",
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ec2267",
   "metadata": {},
   "source": [
    "Мы получаем таблицу, в которой каждый столбец соответствует слову из сформированного словаря, а строка - фразе из исходного корпуса (набора) текстов. Если взглянуть на таблицу и на словарь, видно, что на пересечении находится количество, сколько раз встречается определенное слово в определенном тексте.\n",
    "\n",
    "Словарь составляется автоматически в лексикографическом порядке.\n",
    "\n",
    "Уже здесь вы можете указать на значительное упущение, сделанное мной намеренно, и которое может создать сложности при дальнейшей работе. Об этом поговорим позже, а пока применим векторизатор к нашим даным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9756e2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a327d4",
   "metadata": {},
   "source": [
    "В библиотеке `sklearn` есть несколько моделей наивного байесса, мы возьмем полиномиальную, она хорошо работает как раз с данной векторизацией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafcf854",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b153bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d8617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test_vec)\n",
    "metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c48f43",
   "metadata": {},
   "source": [
    "Не самые плохие результаты.\n",
    "\n",
    "Но можно ли улучшить показатели модели? И за счет чего?\n",
    "\n",
    "---\n",
    "`CountVectorizer` будет создавать выбросы для слишком асто встречающихся слов, из-за чего будут занижаться значения для некоторых важных слов. Чтобы этого избежать, попробуем использовать другой векторизатор, TF-IDF.\n",
    "\n",
    "> Термины \"TF\" (Term Frequency) и \"IDF\" (Inverse Document Frequency).\n",
    ">\n",
    "> TF (Частота термина) обозначает, насколько часто определенное слово появляется в данном документе. Таким образом, TF измеряет важность слова в контексте отдельного документа.\n",
    ">\n",
    "> IDF (Обратная частота документа) измеряет, насколько уникально слово является по всей коллекции документов. Слова, которые появляются в большинстве документов, имеют низкое IDF, так как они не вносят большой информационной ценности.\n",
    "\n",
    "Формула TF-IDF комбинирует понятия TF и IDF, чтобы вычислить важность каждого слова в каждом документе. Формально, формула выглядит следующим образом:\n",
    "\n",
    "> **TF-IDF(t, d) = TF(t, d) * IDF(t)**\n",
    "\n",
    "Где:\n",
    "\n",
    "TF(t, d) - Частота термина (TF) для слова \"t\" в документе \"d\".\n",
    "\n",
    "IDF(t) - Обратная частота документа (IDF) для слова \"t\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06b3596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e40bb2",
   "metadata": {},
   "source": [
    "Как выглядит таблица и словарь? Напишите код, чтобы посмотреть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311000d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Корпус текстов можете заменить по желанию\n",
    "txt = ['мама мыла раму',\n",
    "      'мама чинила раму',\n",
    "      'мама мыла, мама чинила'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a0d2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed24a5f",
   "metadata": {},
   "source": [
    "А теперь можно обучить модель с использованием данного векторизатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb4f94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e14157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6357e9",
   "metadata": {},
   "source": [
    "Изменения незначительны. На самом деле это связано с устройством самой модели. Даже в документации вы можете прочитать, что модель работает с дискретными целыми значениями. А TF-IDF, как мы видели, дробный. Однако, отметим, что всё равно модель успешно справилась.\n",
    "\n",
    "---\n",
    "Что ещё мы можем сделать?\n",
    "\n",
    "Конечно, мы пропустили первый и важный этап обработки текста. Токенизация. Нам нужно превратить сплошной текст в набор токенов. Да, если разбитьь текст по пробелу, это тоже токены, однако, у нас в текстах могут встречаться числа и символы (иногда они нужны, но зачастую нет), а также одно и то же слово может быть представлено в различных словоформах (приставки, суффиксы, окончания). Со всем этим нужно работать.\n",
    "\n",
    "Для борьбы со словоформами можно использовать два разных алгоритма:\n",
    "\n",
    "> Лемматиза́ция — процесс приведения словоформы к лемме — её нормальной (словарной) форме.\n",
    "\n",
    "> Сте́мминг (англ. stemming — находить происхождение) — это процесс нахождения основы слова для заданного исходного слова.\n",
    "\n",
    "Мы используем лемматизацию, для этого подгрузим библиотеку `pymystem3`, разработанную в Яндекс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdbda01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c74ec7",
   "metadata": {},
   "source": [
    "Мы создадим лемматизатор, а также загрузим список стоп-слов. Это такие слова, которые обычно не несут никакой смысловой нагрузки (союзы, предлоги, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a16607",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mystem()\n",
    "nltk.download('stopwords')\n",
    "stop_words = list(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ca422a",
   "metadata": {},
   "source": [
    "Вот что получается при работе лемматизатора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccb5a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "m.lemmatize('Интересного текста много не бывает')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db7cdae",
   "metadata": {},
   "source": [
    "Также накинем регулярные выражения, чтоы оставить в каждом тексте только русские буквы. И лемматизируем полученные тексты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7e8772",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ru = [\" \".join(re.sub(r'[^а-яА-ЯёЁ]', ' ', text).split()) for text in X_train.values.astype('U')]\n",
    "train_full = ' br '.join(train_ru)\n",
    "train_lem = (''.join([word for word in m.lemmatize(train_full) if word != '\\n'])).split(' br ')\n",
    "\n",
    "test_ru = [\" \".join(re.sub(r'[^а-яА-ЯёЁ]', ' ', text).split()) for text in X_test.values.astype('U')]\n",
    "test_full = ' br '.join(test_ru)\n",
    "test_lem = (''.join([word for word in m.lemmatize(test_full) if word != '\\n'])).split(' br ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cef8dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65753cbf",
   "metadata": {},
   "source": [
    "А теперь к уже обработанному корпусу применим векторизатор и построим модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617befeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "X_train_lem = tfidf_vectorizer.fit_transform(train_lem)\n",
    "X_test_lem = tfidf_vectorizer.transform(test_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27be0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train_lem, y_train)\n",
    "y_pred = model.predict(X_test_lem)\n",
    "metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f8b527",
   "metadata": {},
   "source": [
    "Результат стал даже чуть хуже, но вспомним об особенностях работы модели и попробуем это исправить. Попробуйте получить лучшие метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5e731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7e4cd3",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "\n",
    "---\n",
    "Переходим к следующей модели.\n",
    "\n",
    "Для обучения возьмем данные по диабету."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb8fb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = pd.read_csv('diabetes_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566e2381",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(diabetes.drop(['Outcome'], axis=1), diabetes['Outcome'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b04a6d",
   "metadata": {},
   "source": [
    "Для логистической регрессии обязательно нужно нормализовать данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47253c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111c2fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7556e2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5f8e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(random_state=42).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f006a65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc45a38",
   "metadata": {},
   "source": [
    "Однако, вы помните, что классы в этом датасете несббалансированны, а это не очень хорошо. Но логистическая модель может сама обучаться с поправкой на дисбаланс, главное указать это в аргументах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81378cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(class_weight='balanced', random_state=42).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557965cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83377048",
   "metadata": {},
   "source": [
    "Рассмотрим ещё две метрики, позволяющие оценить качество модели. ROC-кривая и ROC-AUC.\n",
    "\n",
    "---\n",
    "Для построения этих показателей необходимо рассмотреть изменение порога классификации. Поскольку у нас всего два класса, можно рассматривать вероятность получения класса \"1\". По умолчанию порог равен 0.5 - получили значение выше 0.5, класс \"1\", ниже - \"0\".\n",
    "\n",
    "Но этот порог можно изменять. Как будут вести себя точность и полнота, если снизить порог до 0.3? А если повысить до 0.8?\n",
    "\n",
    "У логистической регрессии есть метод `predict_proba`, который автоматически считает вероятности для классов при различном пороге классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8bfee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e9005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = clf.predict_proba(X_test)\n",
    "proba_one = proba[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb2e6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda8a6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db888508",
   "metadata": {},
   "source": [
    "Нам нужны два важных значения. Вспомним матрицу ошибок\n",
    "\n",
    "---\n",
    "|           | Predicted: 0 | Predicted:1 |\n",
    "|-----------|:------------:|:-----------:|\n",
    "| Actual: 0 | TN           | FP          |\n",
    "| Actual: 1 | FN           | TP          |\n",
    "\n",
    "---\n",
    "$TPR = \\frac{TP}{TP+FN}$\n",
    "\n",
    "$FPR = \\frac{FP}{FP+TN}$\n",
    "\n",
    "Что отражают TPR и FPR?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54234fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, proba_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2366b68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "\n",
    "# ROC-кривая случайной модели (выглядит как прямая)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC-кривая')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a257e91b",
   "metadata": {},
   "source": [
    "Для данной модели ROC-кривая почти идеальна, это замечательно. А метрика AUC-ROC - это площадь под ROC-кривой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51722b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_roc = roc_auc_score(y_test, y_pred)\n",
    "print('AUC-ROC:',auc_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5a898e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8481b98b",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "---\n",
    "Переходим к ансамблевому методу обучения.\n",
    "\n",
    "Что такое ансамбль? Нет, не песни и пляски, а применительно к нашей теме.\n",
    "\n",
    "> Ансамблевый метод - метод машинного обучения, где несколько моделей обучаются для решения одной и той же проблемы и объединяются для получения лучших результатов.\n",
    "\n",
    "---\n",
    "Есть два наиболее популярных класса ансаблевых методов: бэггинг и бустинг. О первом мы поговорим сейчас, а второй оставим на будущие темы.\n",
    "\n",
    "> Бэггинг (от англ. bootstrap aggregating, бутстрэп-агрегирование) — ансамблевый метаалгоритм, предназначенный для улучшения стабильности и точности алгоритмов машинного обучения, используемых в задачах классификации и регрессии. Алгоритм также уменьшает дисперсию и помогает избежать переобучения.\n",
    "\n",
    "Если задан стандартный тренировочный набор $D$ размера $n$, бэггинг образует $m$ новых тренировочных наборов $D_i$, каждый размером $n′$, путём выборки из $D$ равномерно и с возвратом. При семплинге с возвратом некоторые наблюдения могут быть повторены в каждой $D_i$. Этот вид семплинга известен как бутстрэп-семплинг. Эти $m$ моделей сглаживаются с помощью вышеупомянутых $m$ бутстрэп-выборок и комбинируются путём усреднения (для регрессии) или голосования (для классификации).\n",
    "\n",
    "---\n",
    "Именно так и устроен случайный лес. Но прежде чем обратиться к обучению моделей, пара слов о подготовке данных и выборе признаков. Используем всё те же данные по диабету."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eede9724",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3cfa9e",
   "metadata": {},
   "source": [
    "Конечно, мы схитрим и изначально не будем использовать признак `FamilyHistory`, чтобы заведемо снизить качество модели.\n",
    "\n",
    "Но у нас остаётся ещё 15 признаков. Да, это не так уж много, это не 200 признаков, когда их число точно хочется сократить. Но иногда и при небольшом количестве признаков стоит подумать и, возможно, от чего-то избавиться.\n",
    "\n",
    "Один из простых шагов - убрать сильно коррелированные переменные.\n",
    "\n",
    "Сильно коррелированные друг с другом переменные дают модели одну и ту же информацию, следовательно, для анализа не нужно использовать их все. Например, если набор данных (dataset) содержит признаки «Время в сети» и «Использованный трафик», можно предположить, что они будут в некоторой степени коррелированы, и мы увидим сильную корреляцию, даже если выберем непредвзятый образец данных. В таком случае в модели нужна только одна из этих переменных. Если использовать обе, то модель окажется переобучена (overfit) и предвзята относительно одного отдельного признака.\n",
    "\n",
    "Посмотрите на корреляционную матрицу и поищите, какие признаки могут быть удалены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34edea65",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "plt.title('Корреляционная матрица')\n",
    "sns.heatmap(diabetes.corr(), cmap='bwr', center=0, annot=True, fmt='.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f75c44",
   "metadata": {},
   "source": [
    "Обучим простую модель случайного леса. Исключаю `FamilyHistory` для снижения метрик, глубину деревьев беру рандомно, число никак не подбиралось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc8666c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecb883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(diabetes.drop(['Outcome', 'FamilyHistory'], axis=1), diabetes['Outcome'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d20d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=8, random_state=42).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2528fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics(y_test, rf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1dbafd",
   "metadata": {},
   "source": [
    "А теперь повторим процесс, но из признаков исключим также `HbA1c`. Он сильно коррелирует с `Glucose`, а значит, они несут очень схожую информацию для модели. Посмотрим, к чему это приведет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2066ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(diabetes.drop(['Outcome', 'FamilyHistory', 'HbA1c'], axis=1), diabetes['Outcome'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3edf138",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=8, random_state=42).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71013c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics(y_test, rf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c1b525",
   "metadata": {},
   "source": [
    "Изменения почти отсутсвуют, но всё же есть, и в лучшую сторону. Значит такой подход к выбору признаков работает.\n",
    "\n",
    "Есть множество способов отбора признаков, о некоторых поговорим, когда будем работать с регрессией.\n",
    "\n",
    "А ещё можно посмотреть на важность признаков в обученной модели с помощью метода `feature_importances_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed660772",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(data=rf.feature_importances_, index=X_train.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaac4587",
   "metadata": {},
   "source": [
    "Попробуйте построить ту же модель, исключив неважные признаки, изменится ли качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb62f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb5241f",
   "metadata": {},
   "source": [
    "Также посмотрим на ROC-кривую для такой модели (у случайного леса тоже есть такие методы)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdeed949",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, rf.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af350aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "\n",
    "# ROC-кривая случайной модели (выглядит как прямая)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC-кривая')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4702114",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_roc = roc_auc_score(y_test, rf.predict(X_test))\n",
    "print(auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a261af",
   "metadata": {},
   "source": [
    "## GridSearchCV\n",
    "\n",
    "---\n",
    "В прошлый раз мы говорили о кросс-валидации, которая помогает получить более правильные метрики при усреднении нескольких моделей.\n",
    "\n",
    "Но куда важнее для модели подобрать нужные гиперпараметры, от этого зависит очень многое, метрики могут отличаться значительно. Самое простое, что можно сделать - ручной перебор, меняем гиперпараметр, обучаем, проверяем, и так по кругу, пока не получим оптимальный результат. Но, это скучно и утомительно, поэтому можно воспользоваться `GridSearchCV`, который проделает тот же процесс самостоятельно. Более того, он попутно проводит и кросс-валидацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd74dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(diabetes.drop(['Outcome', 'FamilyHistory'], axis=1), diabetes['Outcome'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40513e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94096314",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916f36b4",
   "metadata": {},
   "source": [
    "В `SridSearchCV` мы передаем нужную нам модель и перечень гиперпараметров, которые хотим варьировать, с желаемыми значениями. Также можно указать, на сколько частей бить данные при кросс-валидации, и желаемую метрику. Сколько раз будет обучаться модель при следующих параметрах?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0ab0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'max_depth': [5, 8], 'n_estimators': [50, 100], 'random_state': [42]}\n",
    "clf = GridSearchCV(rf, parameters, cv=5, scoring='roc_auc')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91800b54",
   "metadata": {},
   "source": [
    "А после обучения можно посмотреть на лучшую оценку, лучшую модель и просто посмотреть на все результаты обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b26348",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa4a813",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a58b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf2a0eb",
   "metadata": {},
   "source": [
    "Попробуйте использовать `GridSearchCV` с тем набором признаков, который считаете оптимальным. Подберите лучший набор гиперпараметров, выберите метрику и посмотрите, какого результата сможете достичь.\n",
    "\n",
    "Метрики можно посмотреть тут: [scoring-parameter](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991f8594",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "# этот код позволяет вывести итоговое время выполнения ячейки, если вам интересно засечь время обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10790d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81aec8e",
   "metadata": {},
   "source": [
    "## Multiclass classification\n",
    "\n",
    "---\n",
    "Всюду до этого мы рассматривали случаи бинарной классификации, где у нас были только два класса. Однако зачастую нам нужно классифицировать данные по нескольким группам. Есть два подхода к использванию бинарных классификаторов для многоклассовой классификации.\n",
    "\n",
    "> Один против всех (One-versus-all, OvA или один против остальных, One-versus-rest, OvR). Для каждого класса строится один бинарный классификатор. При этом примеры класса определяются как «положительные», а всех других — как «отрицательные». Итоговый результат формируется по принципу «победитель получает все»: объект будет отнесен к классу, для которого бинарный классификатор даст большее число «положительных» примеров.\n",
    "\n",
    "> Один против одного (One versus One, OvO). Строится $k(k−1)$ классификаторов, позволяющих различить любую пару примеров разных классов. Алгоритм просматривает все пары примеров с разными метками классов и для каждой решает бинарную задачу $f_{ij}$. В каждом случае для пар $(i,j)$ положительные — все примеры с метками $i$, а отрицательными — с $j$.\n",
    "\n",
    "Какие недостатки можно отметить у обоих способов?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65642301",
   "metadata": {},
   "source": [
    "Но многие модели просто умеют работать с несколькими классами. Например, случайный лес делает это легко.\n",
    "\n",
    "Для демонстрации загрузим новые данные.\n",
    "\n",
    "Этот набор данных содержит исчерпывающую информацию о 2392 учениках старших классов, в которой подробно описываются их демографические данные, привычки в учебе, участие родителей, внеклассные мероприятия и успеваемость. Целевая переменная, `GradeClass`, классифицирует оценки учеников по отдельным категориям, предоставляя надежный набор данных для образовательных исследований, прогнозного моделирования и статистического анализа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf78bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stud = pd.read_csv('Student_performance_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b24b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "stud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91c7485",
   "metadata": {},
   "source": [
    "Теперь обучим модель и посмотрим на метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183649ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(stud.drop(['GradeClass'], axis=1), stud['GradeClass'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac5c4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(max_depth=8).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cec2899",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics(y_test, rf.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcc4379",
   "metadata": {},
   "source": [
    "Как видим, теперь для каждого класса у нас есть набор метрик, а также общие оценки.\n",
    "\n",
    "И тепловая карта с матрицей ошибок выглядит лучше. Однако на ней заметен дисбаланс классов. А когда мы хотим оценить, где модель делает наибольшие ошибки, нам лучше занулить диагональ. Для этого в нашей функции `metrics` предусмотрен код."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ebffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics(y_test, rf.predict(X_test), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46075984",
   "metadata": {},
   "source": [
    "Тут видно, где модель ошибается боьше всего.\n",
    "\n",
    "В завершение предлагаю вам настроить и эту модель, подобрав лучшие гиперпараметры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43203a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ваш код\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84fccdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
